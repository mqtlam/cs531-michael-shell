\section{Algorithm}\label{sec:alg}

The algorithm consists of two major components: constraint propagation and backtracking search. In fact, the constraint propagation step is incorporated into the backtracking search. Some puzzles could be solved with just an application of the constraint propagation. Other puzzles require search.

\subsection{Constraint Propagation}

The constraint propagation step applies the following rules to the SuDoKu board to reduce the domain values for variables:

\begin{description}
	\item[Rule 1] Assign to any cell a value $x$ if it is the only value left in its domain.
	\item[Rule 2] Assign to any cell a value $x$ if $x$ is not in the domain of any other cell in that row, column or box.
	\item[Rule 3] In any row, column or box, find $k$ squares that each have a domain that contains the same $k$ numbers or a subset of those numbers. Then remove those $k$ numbers from the domains of all other cells of that unit.
\end{description}

Afterwards, these rules are ``propagated'' across the board, updating the board to be consistent with the new assignments.

\subsection{Backtracking Search}

Backtracking search is a depth first search algorithm. For each step of the algorithm, it picks a variable to assign a value and performs constraint propagation. If there is a contradiction after the constraint propagation step, the search discards that assignment and backtracks. If the constraint propagation step was successful, then the search continues making another assignment. The search continues until it finds a complete assignment that satisfies the puzzle, otherwise returns a failure.

There are several heuristics that can be implemented for the backtracking search. For our project, there are two different heuristics for choosing the variable to assign:

\begin{itemize}
	\item Pick the most constrained square (i.e. the variable with the least number of domain values other than those already assigned)
	\item Pick a random square
\end{itemize}

%\begin{algorithm}[H]
%\caption{A* Search}
%\label{alg1}
%\begin{algorithmic}
%\STATE exploredSet = $\emptyset$ 
%\STATE frontier = [initialPath]
%\WHILE{number(explored) $<$ NMAX}
%\IF{frontier == $\emptyset$}
%    \RETURN FALSE
%\ENDIF
%\STATE path = frontier.pop()
%\STATE state = path[0]
%\STATE exploredSet.add(state)
%\IF{state == goalState}
%    \RETURN path
%\ENDIF
%\FOR{action in state.validActions()}
%    \FOR{newState in action.results()}
%        \STATE newPath = path + newState
%        \IF{ismember(frontier,newPath) == FALSE}
%            \STATE frontier.push(newPath)
%        \ENDIF
%    \ENDFOR
%\ENDFOR
%\ENDWHILE
%\end{algorithmic}
%\end{algorithm}

